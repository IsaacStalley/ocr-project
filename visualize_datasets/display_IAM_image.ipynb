{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image, ImageEnhance, ImageOps, ImageFilter, ImageDraw\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "class IAMDataset():\n",
    "    def __init__(self, dataset_dir):\n",
    "        self.root_dir = dataset_dir\n",
    "        self.image_paths = []\n",
    "        self.annotations = {}\n",
    "        self.boxes = []\n",
    "        self.labels = []\n",
    "        self.img_height = 32\n",
    "        self.img_width = 100\n",
    "        self._load_data()\n",
    "\n",
    "    def _load_data(self):\n",
    "        # Iterate through files in the dataset directory\n",
    "        image_path = os.path.join(self.root_dir, 'formsA-D')\n",
    "        for file_name in os.listdir(image_path):\n",
    "            if file_name.endswith('.png'):\n",
    "                self.image_paths.append(file_name)\n",
    "                self.annotations[file_name] = []\n",
    "\n",
    "        # Load annotations from words.txt\n",
    "        annotation_path = os.path.join(self.root_dir, 'ascii/words.txt')\n",
    "        with open(annotation_path, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "\n",
    "        # Process annotations\n",
    "        for line in lines:\n",
    "            if not line.startswith('#'):\n",
    "                parts = line.strip().split()\n",
    "                image_id = parts[0].split(\"-\")[0] + \"-\" + parts[0].split(\"-\")[1]\n",
    "                image_path = f'{image_id}.png'\n",
    "                if image_path in self.annotations:\n",
    "                    self.annotations[image_path].append((parts[3:7], parts[-1]))  # Append bounding box coordinates and word label\n",
    "\n",
    "        # Extract word images and labels\n",
    "        self.word_images = []\n",
    "        self.word_labels = []\n",
    "        for image_path, annotations in self.annotations.items():\n",
    "            image = Image.open(os.path.join(self.root_dir, 'formsA-D', image_path)).convert('L')\n",
    "            for annotation, label in annotations:\n",
    "                # Extract bounding box coordinates\n",
    "                x_min, y_min, width, height = map(int, annotation)\n",
    "                if x_min < 0 or y_min < 0 or width < 0 or height < 0:\n",
    "                    continue \n",
    "\n",
    "                x_max = x_min + width\n",
    "                y_max = y_min + height\n",
    "                assert x_min < x_max\n",
    "                # Crop word image using bounding box coordinates\n",
    "                word_image = image.crop((x_min, y_min, x_max, y_max))\n",
    "                word_image = word_image.resize((self.img_width, self.img_height), resample=Image.BILINEAR)\n",
    "                #word_image = np.array(word_image)\n",
    "                #word_image = word_image.reshape((1, self.img_height, self.img_width))\n",
    "                #word_image = (word_image / 127.5) - 1.0\n",
    "                self.word_images.append(word_image)\n",
    "                self.word_labels.append(label)  # Append word label\n",
    "        \n",
    "    # Function to randomly adjust exposure\n",
    "    def random_exposure(self, image):\n",
    "        factor = random.uniform(0.2, 1.2)  # adjust exposure by a factor between 0.5 and 1.5\n",
    "        enhancer = ImageEnhance.Brightness(image)\n",
    "        return enhancer.enhance(factor)\n",
    "\n",
    "    # Function to randomly invert colors\n",
    "    def random_invert(self, image):\n",
    "        if random.random() < 0.1:  # 50% chance of inverting colors\n",
    "            return ImageOps.invert(image)\n",
    "        else:\n",
    "            return image\n",
    "\n",
    "    # Function to randomly change colors\n",
    "    def random_color_jitter(self, image):\n",
    "        r, g, b = image.split()\n",
    "        r = np.array(r)\n",
    "        g = np.array(g)\n",
    "        b = np.array(b)\n",
    "\n",
    "        r_shift = random.randint(-50, 50)\n",
    "        g_shift = random.randint(-50, 50)\n",
    "        b_shift = random.randint(-50, 50)\n",
    "\n",
    "        r = np.clip(r + r_shift, 0, 255)\n",
    "        g = np.clip(g + g_shift, 0, 255)\n",
    "        b = np.clip(b + b_shift, 0, 255)\n",
    "\n",
    "        r = Image.fromarray(r).convert('L')\n",
    "        g = Image.fromarray(g).convert('L')\n",
    "        b = Image.fromarray(b).convert('L')\n",
    "\n",
    "        return Image.merge('RGB', (r, g, b))\n",
    "\n",
    "\n",
    "    # Function to randomly apply Gaussian blur\n",
    "    def random_blur(self, image):\n",
    "        kernel_size = random.randint(0, 2) * 2 + 1  # Choose an odd kernel size between 3 and 11\n",
    "        return image.filter(ImageFilter.GaussianBlur(kernel_size))\n",
    "\n",
    "    # Function to randomly add noise to the image\n",
    "    def random_noise(self, image):\n",
    "        width, height = image.size\n",
    "        noise = np.random.randint(0, 10, (height, width, 3), dtype=np.uint8)\n",
    "        return Image.fromarray(np.clip(np.array(image) + noise, 0, 255).astype(np.uint8))\n",
    "\n",
    "    # Apply random transformations to the image\n",
    "    def apply_random_transformations(self, image):\n",
    "        image = self.random_exposure(image)\n",
    "        image = self.random_invert(image)\n",
    "        image = self.random_color_jitter(image)\n",
    "        image = self.random_blur(image)\n",
    "        #image = self.random_noise(image)\n",
    "        return image\n",
    "    \n",
    "\n",
    "    def display_image(self, image_id):\n",
    "        #image_id = self.image_paths[image_id]\n",
    "        #image_path = os.path.join(self.root_dir, 'formsA-D')\n",
    "        #image_path = os.path.join(image_path, image_id)\n",
    "\n",
    "        # Load image\n",
    "        image = self.word_images[image_id]\n",
    "        label = self.word_labels[image_id]\n",
    "        image = image.convert('RGB')\n",
    "        image = self.apply_random_transformations(image)\n",
    "        draw = ImageDraw.Draw(image)\n",
    "        draw.text((0,0,0,0),label, fill=\"blue\")\n",
    "        '''\n",
    "        # Find highest and lowest bounding boxes\n",
    "        highest_y_min = float('inf')\n",
    "        lowest_y_max = -1\n",
    "        for bbox in self.annotations[image_id]:\n",
    "            y_min = int(bbox[1])\n",
    "            y_max = y_min + int(bbox[3])\n",
    "            if y_max < 0 or y_min < 0:\n",
    "                continue\n",
    "            highest_y_min = min(highest_y_min, y_min)\n",
    "            lowest_y_max = max(lowest_y_max, y_max)\n",
    "        \n",
    "        threshold=10\n",
    "        # Add threshold\n",
    "        highest_y_min = max(0, highest_y_min - threshold)\n",
    "        lowest_y_max = min(image.height, lowest_y_max + threshold)\n",
    "\n",
    "        # Crop image\n",
    "        image = image.crop((0, highest_y_min, image.width, lowest_y_max))\n",
    "\n",
    "        # Draw bounding boxes\n",
    "        draw = ImageDraw.Draw(image)\n",
    "        for bbox in self.annotations[image_id]:\n",
    "            x_min, y_min, width, height = map(int, bbox)\n",
    "            if x_min < 0 or y_min < 0 or width < 0 or height < 0:\n",
    "                continue \n",
    "\n",
    "            x_max = x_min + width\n",
    "            y_max = y_min + height\n",
    "            assert x_min < x_max\n",
    "            #draw.rectangle([x_min, y_min - highest_y_min, x_max, y_max - highest_y_min], outline=\"red\")\n",
    "'''\n",
    "        # Show image\n",
    "        #image.save(\"../test_images/new.png\")\n",
    "        image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m images_folder \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mIsaacStalley\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDocuments\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mGitHub\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mIAM-dataset\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      3\u001b[0m annotation_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mIsaacStalley\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDocuments\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mGitHub\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mIAM-dataset\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mascii\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mwords.txt\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 5\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mIAMDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages_folder\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[1], line 15\u001b[0m, in \u001b[0;36mIAMDataset.__init__\u001b[1;34m(self, dataset_dir)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimg_height \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m32\u001b[39m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimg_width \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m\n\u001b[1;32m---> 15\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[1], line 43\u001b[0m, in \u001b[0;36mIAMDataset._load_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mword_labels \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m image_path, annotations \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mannotations\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m---> 43\u001b[0m     image \u001b[38;5;241m=\u001b[39m \u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroot_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mformsA-D\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mL\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     44\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m annotation, label \u001b[38;5;129;01min\u001b[39;00m annotations:\n\u001b[0;32m     45\u001b[0m         \u001b[38;5;66;03m# Extract bounding box coordinates\u001b[39;00m\n\u001b[0;32m     46\u001b[0m         x_min, y_min, width, height \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mint\u001b[39m, annotation)\n",
      "File \u001b[1;32mc:\\Users\\IsaacStalley\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\PIL\\Image.py:922\u001b[0m, in \u001b[0;36mImage.convert\u001b[1;34m(self, mode, matrix, dither, palette, colors)\u001b[0m\n\u001b[0;32m    874\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconvert\u001b[39m(\n\u001b[0;32m    875\u001b[0m     \u001b[38;5;28mself\u001b[39m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, matrix\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dither\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, palette\u001b[38;5;241m=\u001b[39mPalette\u001b[38;5;241m.\u001b[39mWEB, colors\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m256\u001b[39m\n\u001b[0;32m    876\u001b[0m ):\n\u001b[0;32m    877\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    878\u001b[0m \u001b[38;5;124;03m    Returns a converted copy of this image. For the \"P\" mode, this\u001b[39;00m\n\u001b[0;32m    879\u001b[0m \u001b[38;5;124;03m    method translates pixels through the palette.  If mode is\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    919\u001b[0m \u001b[38;5;124;03m    :returns: An :py:class:`~PIL.Image.Image` object.\u001b[39;00m\n\u001b[0;32m    920\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 922\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    924\u001b[0m     has_transparency \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransparency\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfo\n\u001b[0;32m    925\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m mode \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mP\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    926\u001b[0m         \u001b[38;5;66;03m# determine default mode\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\IsaacStalley\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\PIL\\ImageFile.py:291\u001b[0m, in \u001b[0;36mImageFile.load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    288\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(msg)\n\u001b[0;32m    290\u001b[0m b \u001b[38;5;241m=\u001b[39m b \u001b[38;5;241m+\u001b[39m s\n\u001b[1;32m--> 291\u001b[0m n, err_code \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    292\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    293\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Path to the folder containing images\n",
    "images_folder = r'C:\\Users\\IsaacStalley\\Documents\\GitHub\\IAM-dataset'\n",
    "annotation_path = r'C:\\Users\\IsaacStalley\\Documents\\GitHub\\IAM-dataset\\ascii\\words.txt'\n",
    "\n",
    "dataset = IAMDataset(images_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset.display_image(100000)  # Display the first image with annotations"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
